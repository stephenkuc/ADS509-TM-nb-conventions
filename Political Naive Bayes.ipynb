{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "### Stephen Kuc\n",
    "### ADS509\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "# from text_function_solutions import descriptive_stats, remove_stop,  tokenize, prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "sw = set(sw)\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# and now our functions\n",
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "\n",
    "    \n",
    "    # finding total number of tokens by the length of tokens list\n",
    "    num_tokens = len(tokens)\n",
    "    \n",
    "    # creating a set of tokens to find unique, and then length of that\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    \n",
    "    # dividing unique over total to find diversity\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    \n",
    "    \n",
    "    # creating a quick for-loop to cound all characters in document\n",
    "    num_characters_list = []\n",
    "    for word in tokens:\n",
    "        num_characters_list.append(len(word))\n",
    "        \n",
    "    num_characters = sum(num_characters_list)\n",
    "    \n",
    "    # utilizing Counter to count the characters and then finding the top 5\n",
    "    \n",
    "    common_count = Counter(tokens)\n",
    "    \n",
    "    most_common_five = common_count.most_common(5)\n",
    "    \n",
    "    if verbose == True:        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        print(f\"These are the five most common tokens and their count:\\n {most_common_five}\")\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters, most_common_five])\n",
    "\n",
    "    \n",
    "def remove_stop(tokens) :\n",
    "    \n",
    "    return [t for t in tokens if t.lower() not in sw]\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    text = text.split(' ') # split on whitespace to include hashtags and other information\n",
    "    return(text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "\n",
    "def join_tokens(tokens):\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\") # we are in the same directory\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\"SELECT text, party FROM conventions;\")\n",
    "\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop, join_tokens]\n",
    "\n",
    "convention_table = []\n",
    "\n",
    "for row in query_results :\n",
    "    text, party = row\n",
    "    \n",
    "    convention_table.append((text, party))\n",
    "\n",
    "    \n",
    "    \n",
    "convention_df = pd.DataFrame(convention_table, columns = [\"text\", \"party\"])\n",
    "\n",
    "tokens = convention_df['text'].apply(prepare, pipeline = my_pipeline)\n",
    "\n",
    "convention_df['text'] = tokens\n",
    "\n",
    "convention_data = convention_df.values.tolist()\n",
    "\n",
    "# there must be a better way to do this \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tennessee', 'Democratic'],\n",
       " ['good evening it’s honor come tonight commonwealth kentucky leader washington either new york california consider responsibility look middle america election incredibly consequential middle america president trump knows inherited first generation americans couldn’t promise children better life he’s made mission administration change know work beside every day today’s democrat party doesn’t want improve life middle america prefer us flyover country keep quiet let decide live lives',\n",
       "  'Republican'],\n",
       " ['let us pray pray must grateful citizens country boldly claim one nation god pray must praising lord country freedom religion cherished republicans democrats begin conventions heads bowed prayer pray must conscious suffering covid unwearied frontliners care us pray must lives may protected respected troubled cities police guard tense world situations men women uniform keep peace innocent life baby womb elders nursing care hospice immigrants refugees lives threatened religious persecution throughout world plague hunger drugs human trafficking war pray must thanksgiving thanksgiving dear god democracy ask hand almighty father upon convention nominees parties wisdom upon electorate eager perform duty faithful citizenship pray dare claim god trust amen',\n",
       "  'Republican'],\n",
       " ['100 years ago tonight suffragists based hermitage hotel nashville cheered tennessee became 36th deciding state ratify 19th amendment granting women right vote year i’m casting first presidential vote joe biden women decide election replace donald trump president respects us tennessee cast 23 votes bernie sanders 50 votes next president united states mr joseph r biden',\n",
       "  'Democratic'],\n",
       " ['good evening folks i’m tony evers i’m incredibly proud 46th governor great state wisconsin really looking forward america’s dairyland unfortunately pandemic means can’t year unites us far far greater divides us even though can’t know shared sense purpose elect joe biden kamala harris november returning kindness respect empathy civility back white house that’s joe kamala know especially challenging times like problems face solved us together holy macro folks let’s get work',\n",
       "  'Democratic'],\n",
       " ['family complete', 'Democratic'],\n",
       " ['new hampshire', 'Democratic'],\n",
       " ['openly gay man georgia state legislature', 'Democratic'],\n",
       " ['want freedom gradually want free', 'Democratic'],\n",
       " ['people say “we’re oppressed united states”', 'Republican']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ret_dict = dict()\n",
    "    \n",
    "    words = text.split(\" \") # splitting words on white space to create as tokens again\n",
    "    \n",
    "    for w in words: \n",
    "        if w in fw: # checking if word is included in feature words\n",
    "            ret_dict[w] = True\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "These are very interesting. Knowing that these were in 2020, when COVID was at its peak, or at least near its peak, it is pretty apparent that it was an issue talked about. The Republicans seem to like to blame China, or at least utilize China as, presumably, an enemy, although, we can't fully come to that that's how they're using \"China\" in their speeches with just this information. \n",
    "\n",
    "23 of the 25 most important features were all with Republicans saying a certain word at least 10x more than Democrats. So, it seems that they utilize these American-like buzz words, like \"destroy\", \"freedoms\", \"beliefs\", \"liberal\" \"religion\", \"flag\", to try to incite some more pride and possibly nationalism within their supporters. They also mentioned \"enemy\", \"isis\", and again \"china\". These words also seem a bit divisive.\n",
    "\n",
    "Perhaps, that is a bit negative on the Republican party, but that's what this data seems to point to. \n",
    "\n",
    "Within the Democrats, the two words in the top 25 are climate and votes. The democrats seem to utilize less distinct words, and focus in on matters like the climate. They also are probably lobbying for votes and for people to go vote, because perhaps they felt at this point in time, that was the only way they'd lose to the Republicans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "tweet_table = []\n",
    "\n",
    "for row in results :\n",
    "    candidate, party, text = row\n",
    "    \n",
    "    tweet_table.append((text, party))\n",
    "    \n",
    "\n",
    "tweet_df = pd.DataFrame(tweet_table, columns = [\"text\", \"party\"])\n",
    "\n",
    "tokens = tweet_df['text'].apply(prepare, pipeline = my_pipeline)\n",
    "\n",
    "tweet_df['text'] = tokens\n",
    "\n",
    "tweet_data = tweet_df.values.tolist()\n",
    "\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: bearlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bgo tribe #rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bapparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bwexe2x80x99re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives linennhttpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "The classifier was incorrect\n",
      " \n",
      "Here's our (cleaned) tweet: bletxe2x80x99s make even greater  #kag xf0x9fx87xbaxf0x9fx87xb8 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "The classifier was incorrect\n",
      " \n",
      "Here's our (cleaned) tweet: bwe 1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bcongrats belliottsd new gig sd city hall glad continue servexe2x80xa6 httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bwe really close 3500 raised toward match right whoot thatxe2x80x99s 7000 nonmath majors room xf0x9fx98x82 help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: btoday comment period potusxe2x80x99s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bcelebrated icseastlaxe2x80x99s 22 years eastside commitment amp saluted community leaders last nightxe2x80x99s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bperrynelson thanks\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n",
      "Here's our (cleaned) tweet: bgreat #ag news today xe2x86x92  restoring #trade access china us #beef producers incredible step forward httpstcorpl2dw3dec\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "The classifier was incorrect\n",
      " \n",
      "Here's our (cleaned) tweet: bicyminnon bluevirginia jennifer discusses need replace politicians blame mentally ill acts gun violencennhttpstcoilynevbpqw\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "The classifier was correct\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    featureset_twt = conv_features(tweet, party) # feature directory\n",
    "    \n",
    "    estimated_party = classifier.classify(featureset_twt)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    if party == estimated_party:\n",
    "        print(\"The classifier was correct\")\n",
    "    else:\n",
    "        print(\"The classifier was incorrect\")\n",
    "    print(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "    \n",
    "    featureset_twt = conv_features(tweet, party) # feature directory\n",
    "    \n",
    "    estimated_party = classifier.classify(featureset_twt)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 4, 'Democratic': 4369}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 0, 'Democratic': 5629})})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "It appears that the classifier virtually always picks Democrats with tweets. One reason that may be the cause and express some error in the application of the model is that nobody tweets like politicians give speeches. Part of the twitter data has hashtags, links, and other typos and errors, which would need further cleaning to better match the training data. There was only very slight class imbalance; not enough to affect the overwhelming majority of democrats to be picked.\n",
    "\n",
    "Since it is a Naive Bayes classifier, it is going off the assumption that every pair of features is independent of each other, which is not the case for text or speech. As it's going off of probabilities of determining the class of a tweet based on its text, and the speech data was the training data, it goes back to the mismatch of the corpus in terms of the context of the actual text, and the different words likely used in speeches versus on twitter.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
